{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGRGRvxzbg6NlcgjvdPdY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohanrathod7/my-ml-labs/blob/main/08_Extreme_Gradient_Boosting_with_XGBoost/01_Classification_with_XGBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Classification with XGBoost"
      ],
      "metadata": {
        "id": "69GNV3tpDLy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EUPpAj0HoP6i"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "# Import confusion matrix and train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression, LinearRegression\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Supervized Learning"
      ],
      "metadata": {
        "id": "thIz_8vxfakh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which of these is a classification problem?**  \n",
        "Given below are 4 potential machine learning problems you might encounter in the wild. Pick the one that is a classification problem.\n",
        "\n",
        "- Given past performance of stocks and various other financial data, predicting the exact price of a given stock (Google) tomorrow.\n",
        "\n",
        "[No - Not quite. This is an example of a regression problem, because we are predicting a continuous quantity.]\n",
        "\n",
        "\n",
        "\n",
        "- Given a large dataset of user behaviors on a website, generating an informative segmentation of the users based on their behaviors.\n",
        "\n",
        "*[No - There's nothing to predict here, this is an unsupervised (clustering) problem.]*\n",
        "\n",
        "\n",
        "- --Predicting whether a given user will click on an ad given the ad content and metadata associated with the user.\n",
        "\n",
        "\n",
        "\n",
        "- Given a user's past behavior on a video platform, presenting him/her with a series of recommended videos to watch next.\n",
        "\n",
        "[No - Incorrect. This problem involves ranking entities and returning the highest ranked ones (in order) to the user.]\n"
      ],
      "metadata": {
        "id": "dw2Yh6YifPOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which of these is a binary classification problem?**   \n",
        "Great! A classification problem involves predicting the category a given data point belongs to out of a finite set of possible categories. Depending on how many possible categories there are to predict, a classification problem can be either binary or multi-class. Let's do another quick refresher here. Your job is to pick the binary classification problem out of the following list of supervised learning problems.\n",
        "\n",
        "- -- Predicting whether a given image contains a cat. [A binary classification problem involves picking between 2 choices.]\n",
        "\n",
        "\n",
        "- Predicting the emotional valence of a sentence (Valence can be positive, negative, or neutral).\n",
        "\n",
        "\n",
        "- Recommending the most tax-efficient strategy for tax filing in an automated accounting system.\n",
        "\n",
        "\n",
        "- Given a list of symptoms, generating a rank-ordered list of most likely diseases."
      ],
      "metadata": {
        "id": "X_TzUL6nfgOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "PIzre1Jdim7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost: Fit/Predict**  \n",
        "It's time to create your first XGBoost model! As Sergey showed you in the video, you can use the scikit-learn .fit() / .predict() paradigm that you are already familiar to build your XGBoost models, as the xgboost library has a scikit-learn compatible API!\n",
        "\n",
        "Here, you'll be working with churn data. This dataset contains imaginary data from a ride-sharing app with user behaviors over their first month of app usage in a set of imaginary cities as well as whether they used the service 5 months after sign-up. It has been pre-loaded for you into a DataFrame called churn_data - explore it in the Shell!\n",
        "\n",
        "Your goal is to use the first month's worth of data to predict whether the app's users will remain users of the service at the 5 month mark. This is a typical setup for a churn prediction problem. To do this, you'll split the data into training and test sets, fit a small xgboost model on the training set, and evaluate its performance on the test set by computing its accuracy.\n",
        "\n",
        "pandas and numpy have been imported as pd and np, and train_test_split has been imported from sklearn.model_selection. Additionally, the arrays for the features and the target have been created as X and y."
      ],
      "metadata": {
        "id": "N2RTMPMIiTWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import xgboost\n",
        "import xgboost as xgb\n",
        "import pandas as pd # Import pandas\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Rohanrathod7/my-ml-labs/main/08_Extreme_Gradient_Boosting_with_XGBoost/dataset/churn_data.csv\"\n",
        "# Read the CSV file\n",
        "# The original code tried to read a feather file as a CSV, and had a UnicodeDecodeError.\n",
        "# The file extension is feather, so it should be read using pd.read_feather.\n",
        "# Also, the variable name was confusing, it should be spotify_population.\n",
        "churn_data = pd.read_csv(url)\n",
        "display(churn_data.head())\n",
        "\n",
        "\n",
        "# Create arrays for the features and the target: X, y\n",
        "X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]\n",
        "\n",
        "# Create the training and test sets\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# Instantiate the XGBClassifier: xg_cl\n",
        "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n",
        "\n",
        "# Fit the classifier to the training set\n",
        "xg_cl.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set: preds\n",
        "preds = xg_cl.predict(X_test)\n",
        "\n",
        "# Compute the accuracy: accuracy\n",
        "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]\n",
        "print(\"accuracy: %f\" % (accuracy))\n",
        "\n",
        "\n",
        "# Your model has an accuracy of around 74%. In Chapter 3, you'll learn about ways to fine tune your XGBoost models.\n",
        "# For now, let's refresh our memories on how decision trees work."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "1ewNEA0KjYY0",
        "outputId": "7e81ee6d-6e8f-46d3-8b12-911596042562"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   avg_dist  avg_rating_by_driver  avg_rating_of_driver  avg_inc_price  \\\n",
              "0      3.67                   5.0                   4.7           1.10   \n",
              "1      8.26                   5.0                   5.0           1.00   \n",
              "2      0.77                   5.0                   4.3           1.00   \n",
              "3      2.36                   4.9                   4.6           1.14   \n",
              "4      3.13                   4.9                   4.4           1.19   \n",
              "\n",
              "   inc_pct  weekday_pct  fancy_car_user  city_Carthag  city_Harko  \\\n",
              "0     15.4         46.2            True             0           1   \n",
              "1      0.0         50.0           False             1           0   \n",
              "2      0.0        100.0           False             1           0   \n",
              "3     20.0         80.0            True             0           1   \n",
              "4     11.8         82.4           False             0           0   \n",
              "\n",
              "   phone_iPhone  first_month_cat_more_1_trip  first_month_cat_no_trips  \\\n",
              "0             1                            1                         0   \n",
              "1             0                            0                         1   \n",
              "2             1                            1                         0   \n",
              "3             1                            1                         0   \n",
              "4             0                            1                         0   \n",
              "\n",
              "   month_5_still_here  \n",
              "0                   1  \n",
              "1                   0  \n",
              "2                   0  \n",
              "3                   1  \n",
              "4                   0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf1ce67d-7534-434e-be62-e6503336b718\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_dist</th>\n",
              "      <th>avg_rating_by_driver</th>\n",
              "      <th>avg_rating_of_driver</th>\n",
              "      <th>avg_inc_price</th>\n",
              "      <th>inc_pct</th>\n",
              "      <th>weekday_pct</th>\n",
              "      <th>fancy_car_user</th>\n",
              "      <th>city_Carthag</th>\n",
              "      <th>city_Harko</th>\n",
              "      <th>phone_iPhone</th>\n",
              "      <th>first_month_cat_more_1_trip</th>\n",
              "      <th>first_month_cat_no_trips</th>\n",
              "      <th>month_5_still_here</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.67</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.10</td>\n",
              "      <td>15.4</td>\n",
              "      <td>46.2</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.26</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.77</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.36</td>\n",
              "      <td>4.9</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.14</td>\n",
              "      <td>20.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.13</td>\n",
              "      <td>4.9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.19</td>\n",
              "      <td>11.8</td>\n",
              "      <td>82.4</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf1ce67d-7534-434e-be62-e6503336b718')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf1ce67d-7534-434e-be62-e6503336b718 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf1ce67d-7534-434e-be62-e6503336b718');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c33760d5-ba7e-47c8-9411-81ffe977c6a4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c33760d5-ba7e-47c8-9411-81ffe977c6a4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c33760d5-ba7e-47c8-9411-81ffe977c6a4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# For now, let's refresh our memories on how decision trees work\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"avg_dist\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.805382326885232,\n        \"min\": 0.77,\n        \"max\": 8.26,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.26,\n          3.13,\n          0.77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_rating_by_driver\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05477225575051641,\n        \"min\": 4.9,\n        \"max\": 5.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.9,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_rating_of_driver\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27386127875258304,\n        \"min\": 4.3,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.0,\n          4.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_inc_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08473488065725941,\n        \"min\": 1.0,\n        \"max\": 1.19,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          1.19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inc_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.094393877548958,\n        \"min\": 0.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0,\n          11.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weekday_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.942362563607087,\n        \"min\": 46.2,\n        \"max\": 100.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          50.0,\n          82.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fancy_car_user\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city_Carthag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"city_Harko\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_iPhone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_month_cat_more_1_trip\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"first_month_cat_no_trips\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month_5_still_here\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.759400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision trees**  \n",
        "Your task in this exercise is to make a simple decision tree using scikit-learn's DecisionTreeClassifier on the breast cancer dataset that comes pre-loaded with scikit-learn.\n",
        "\n",
        "This dataset contains numeric measurements of various dimensions of individual tumors (such as perimeter and texture) from breast biopsies and a single outcome value (the tumor is either malignant, or benign).\n",
        "\n",
        "We've preloaded the dataset of samples (measurements) into X and the target values per tumor into y. Now, you have to split the complete dataset into training and testing sets, and then train a DecisionTreeClassifier. You'll specify a parameter called max_depth. Many other parameters can be modified within this model, and you can check all of them out here."
      ],
      "metadata": {
        "id": "QMItVkBhnAuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create the training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "# Instantiate the classifier: dt_clf_4\n",
        "dt_clf_4 = DecisionTreeClassifier(max_depth=4)\n",
        "\n",
        "# Fit the classifier to the training set\n",
        "dt_clf_4.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set: y_pred_4\n",
        "y_pred_4 = dt_clf_4.predict(X_test)\n",
        "\n",
        "# Compute the accuracy of the predictions: accuracy\n",
        "accuracy = float(np.sum(y_pred_4==y_test))/y_test.shape[0]\n",
        "print(\"accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "# It's now time to learn about what gives XGBoost its state-of-the-art performance: Boosting."
      ],
      "metadata": {
        "id": "razw1HKinOlJ",
        "outputId": "f1d65ca1-ad45-4984-f826-0a346034b8fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Boosting, Model Evaluation (DMatrix)"
      ],
      "metadata": {
        "id": "4oMo4s8ksyiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Measuring accuracy**  \n",
        "You'll now practice using XGBoost's learning API through its baked in cross-validation capabilities. As Sergey discussed in the previous video, XGBoost gets its lauded performance and efficiency gains by utilizing its own optimized data structure for datasets called a DMatrix.\n",
        "\n",
        "In the previous exercise, the input datasets were converted into DMatrix data on the fly, but when you use the xgboost cv object, you have to first explicitly convert your data into a DMatrix. So, that's what you will do here before running cross-validation on churn_data.\n",
        "\n",
        "- Create a DMatrix called churn_dmatrix from churn_data using xgb.DMatrix(). The features are available in X and the labels in y.\n",
        "- Perform 3-fold cross-validation by calling xgb.cv(). dtrain is your churn_dmatrix, params is your parameter dictionary, nfold is the number of cross-validation folds (3), num_boost_round is the number of trees we want to build (5), metrics is the metric you want to compute (this will be \"error\", which we will convert to an accuracy)."
      ],
      "metadata": {
        "id": "0I8pYOYgs6_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create arrays for the features and the target: X, y\n",
        "X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]\n",
        "\n",
        "# Create the DMatrix from X and y: churn_dmatrix\n",
        "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "\n",
        "# Create the parameter dictionary: params\n",
        "params = {\"objective\":\"reg:logistic\", \"max_depth\":3}\n",
        "\n",
        "# Perform cross-validation: cv_results\n",
        "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params,\n",
        "                  nfold=3, num_boost_round=5,\n",
        "                  metrics=\"error\", as_pandas=True, seed=123)\n",
        "\n",
        "# Print cv_results\n",
        "print(cv_results)\n",
        "\n",
        "# Print the accuracy\n",
        "print(((1-cv_results[\"test-error-mean\"]).iloc[-1]))\n",
        "\n",
        "#  cv_results stores the training and test mean and standard deviation of the error per boosting round (tree built) as a DataFrame.\n",
        "#  From cv_results, the final round 'test-error-mean' is extracted and converted into an accuracy, where accuracy is 1-error.\n",
        "#  The final accuracy of around 75% is an improvement from earlier!"
      ],
      "metadata": {
        "id": "tXLGgabCtBVq",
        "outputId": "699252b3-3e6c-41d6-fd13-783192dd9eec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
            "0           0.29625         0.017060          0.29986        0.016645\n",
            "1           0.26915         0.002776          0.27164        0.002463\n",
            "2           0.25611         0.002730          0.25720        0.003823\n",
            "3           0.25160         0.002481          0.25546        0.001942\n",
            "4           0.24764         0.002331          0.24940        0.000435\n",
            "0.750600006600612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Measuring AUC**  \n",
        "Now that you've used cross-validation to compute average out-of-sample accuracy (after converting from an error), it's very easy to compute any other metric you might be interested in. All you have to do is pass it (or a list of metrics) in as an argument to the metrics parameter of xgb.cv().\n",
        "\n",
        "Your job in this exercise is to compute another common metric used in binary classification - the area under the curve (\"auc\"). As before, churn_data is available in your workspace, along with the DMatrix churn_dmatrix and parameter dictionary params."
      ],
      "metadata": {
        "id": "mxGAD_WotQjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform cross_validation: cv_results\n",
        "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params,\n",
        "                  nfold=3, num_boost_round=5,\n",
        "                  metrics=\"auc\", as_pandas=True, seed=123)\n",
        "\n",
        "# Print cv_results\n",
        "print(cv_results)\n",
        "\n",
        "# Print the AUC\n",
        "print((cv_results[\"test-auc-mean\"]).iloc[-1])\n",
        "\n",
        "# An AUC of 0.84 is quite strong. As you have seen, XGBoost's learning API makes it very easy to compute any metric you may be interested in. In Chapter 3,\n",
        "# you'll learn about techniques to fine-tune your XGBoost models to improve their performance even further.\n",
        "# For now, it's time to learn a little about exactly when to use XGBoost."
      ],
      "metadata": {
        "id": "U9wDQlJdt5bQ",
        "outputId": "01e2526d-0df1-4edd-d2ce-8ac1e062e8ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
            "0        0.768844       0.001476       0.767757      0.002737\n",
            "1        0.790677       0.006640       0.788928      0.006727\n",
            "2        0.815537       0.003857       0.814085      0.005832\n",
            "3        0.822564       0.001682       0.821239      0.003626\n",
            "4        0.827401       0.000886       0.826085      0.002024\n",
            "0.8260849495138259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using XGBoost**  \n",
        "XGBoost is a powerful library that scales very well to many samples and works for a variety of supervised learning problems. That said, as Sergey described in the video, you shouldn't always pick it as your default machine learning library when starting a new project, since there are some situations in which it is not the best option. In this exercise, your job is to consider the below examples and select the one which would be the best use of XGBoost."
      ],
      "metadata": {
        "id": "cFqIB0amu2Bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Visualizing the similarity between stocks by comparing the time series of their historical prices relative to each other.\n",
        "\n",
        "`[This is an example of a clustering problem - there are no labels to learn from here.]`\n",
        "\n",
        "\n",
        "- Predicting whether a person will develop cancer using genetic data with millions of genes, 23 examples of genomes of people that didn't develop cancer, 3 genomes of people who wound up getting cancer.\n",
        "\n",
        "`[This would not be an ideal use of XGBoost as there are many more features than there are examples.]`\n",
        "\n",
        "- Clustering documents into topics based on the terms used in them.\n",
        "\n",
        "`[This is an example of a clustering problem. There are no targets and so you cannot use supervised learning.]`\n",
        "\n",
        "\n",
        "- -- Predicting the likelihood that a given user will click an ad from a very large clickstream log with millions of users and their web interactions.\n",
        "\n",
        "`[Way to end the chapter. Time to apply XGBoost to solve regression problems!]`"
      ],
      "metadata": {
        "id": "Y32ylSkpu_xA"
      }
    }
  ]
}