{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqRcwWNkP2cMVSKVbn/gKD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohanrathod7/my-ml-labs/blob/main/08_Extreme_Gradient_Boosting_with_XGBoost/03_Fine-tuning_your_XGBoost_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Fine-tuning your XGBoost model"
      ],
      "metadata": {
        "id": "69GNV3tpDLy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EUPpAj0HoP6i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "aee8f65e-589e-41c2-8e18-c86ecd9ca8be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "0          60         65.0     8450            7            5       2003   \n",
              "1          20         80.0     9600            6            8       1976   \n",
              "2          60         68.0    11250            7            5       2001   \n",
              "3          70         60.0     9550            7            5       1915   \n",
              "4          60         84.0    14260            8            5       2000   \n",
              "\n",
              "   Remodeled  GrLivArea  BsmtFullBath  BsmtHalfBath  ...  HouseStyle_1.5Unf  \\\n",
              "0          0       1710             1             0  ...                  0   \n",
              "1          0       1262             0             1  ...                  0   \n",
              "2          1       1786             1             0  ...                  0   \n",
              "3          1       1717             1             0  ...                  0   \n",
              "4          0       2198             1             0  ...                  0   \n",
              "\n",
              "   HouseStyle_1Story  HouseStyle_2.5Fin  HouseStyle_2.5Unf  HouseStyle_2Story  \\\n",
              "0                  0                  0                  0                  1   \n",
              "1                  1                  0                  0                  0   \n",
              "2                  0                  0                  0                  1   \n",
              "3                  0                  0                  0                  1   \n",
              "4                  0                  0                  0                  1   \n",
              "\n",
              "   HouseStyle_SFoyer  HouseStyle_SLvl  PavedDrive_P  PavedDrive_Y  SalePrice  \n",
              "0                  0                0             0             1     208500  \n",
              "1                  0                0             0             1     181500  \n",
              "2                  0                0             0             1     223500  \n",
              "3                  0                0             0             1     140000  \n",
              "4                  0                0             0             1     250000  \n",
              "\n",
              "[5 rows x 57 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2698053d-72df-41a3-a0f5-9199006cfbcf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>Remodeled</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>...</th>\n",
              "      <th>HouseStyle_1.5Unf</th>\n",
              "      <th>HouseStyle_1Story</th>\n",
              "      <th>HouseStyle_2.5Fin</th>\n",
              "      <th>HouseStyle_2.5Unf</th>\n",
              "      <th>HouseStyle_2Story</th>\n",
              "      <th>HouseStyle_SFoyer</th>\n",
              "      <th>HouseStyle_SLvl</th>\n",
              "      <th>PavedDrive_P</th>\n",
              "      <th>PavedDrive_Y</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>1</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 57 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2698053d-72df-41a3-a0f5-9199006cfbcf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2698053d-72df-41a3-a0f5-9199006cfbcf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2698053d-72df-41a3-a0f5-9199006cfbcf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cd2e0707-ab3d-43ba-b98e-c3be17436126\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd2e0707-ab3d-43ba-b98e-c3be17436126')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cd2e0707-ab3d-43ba-b98e-c3be17436126 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "# Import confusion matrix and train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression, LinearRegression\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Rohanrathod7/my-ml-labs/main/08_Extreme_Gradient_Boosting_with_XGBoost/dataset/ames_housing_trimmed_processed.csv\"\n",
        "# Read the CSV file\n",
        "# The original code tried to read a feather file as a CSV, and had a UnicodeDecodeError.\n",
        "# The file extension is feather, so it should be read using pd.read_feather.\n",
        "# Also, the variable name was confusing, it should be spotify_population.\n",
        "ames_housing_trimmed_processed = pd.read_csv(url).apply(pd.to_numeric, errors='coerce')\n",
        "display(ames_housing_trimmed_processed.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When is tuning your model a bad idea?**  \n",
        "Now that you've seen the effect that tuning has on the overall performance of your XGBoost model, let's turn the question on its head and see if you can figure out when tuning your model might not be the best idea. Given that model tuning can be time-intensive and complicated, which of the following scenarios would NOT call for careful tuning of your model?\n",
        "\n",
        "->\n",
        "You are very short on time before you must push an initial model to production and have little data to train your model on."
      ],
      "metadata": {
        "id": "FrS7YT-FlHk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tuning the number of boosting rounds**  \n",
        "Let's start with parameter tuning by seeing how the number of boosting rounds (number of trees you build) impacts the out-of-sample performance of your XGBoost model. You'll use xgb.cv() inside a for loop and build one model per num_boost_round parameter."
      ],
      "metadata": {
        "id": "Sq31hNLhliDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import xgboost\n",
        "import xgboost as xgb\n",
        "import pandas as pd # Import pandas\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = ames_housing_trimmed_processed.iloc[:,:-1], ames_housing_trimmed_processed.iloc[:,-1]\n",
        "\n",
        "# Create the training and test sets\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "\n",
        "\n",
        "# Create the DMatrix: housing_dmatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "\n",
        "# Create the parameter dictionary for each tree: params\n",
        "params = {\"objective\":\"reg:squarederror\", \"max_depth\":3}\n",
        "\n",
        "# Create list of number of boosting rounds\n",
        "num_rounds = [5, 10, 15]\n",
        "\n",
        "# Empty list to store final round rmse per XGBoost model\n",
        "final_rmse_per_round = []\n",
        "\n",
        "# Iterate over num_rounds and build one model per num_boost_round parameter\n",
        "for curr_num_rounds in num_rounds:\n",
        "\n",
        "    # Perform cross-validation: cv_results\n",
        "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics=\"rmse\", as_pandas=True, seed=123)\n",
        "\n",
        "    # Append final round RMSE\n",
        "    final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "# Print the resultant DataFrame\n",
        "num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n",
        "print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))\n",
        "\n",
        "# As you can see, increasing the number of boosting rounds decreases the RMSE."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxjvX3ulmFql",
        "outputId": "558ddb46-3fd7-4274-ac46-2a7afcf59e67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   num_boosting_rounds          rmse\n",
            "0                    5  40350.042785\n",
            "1                   10  34222.544068\n",
            "2                   15  32537.190260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Automated boosting round selection using early_stopping**  \n",
        "Now, instead of attempting to cherry pick the best possible number of boosting rounds, you can very easily have XGBoost automatically select the number of boosting rounds for you within xgb.cv(). This is done using a technique called early stopping.\n",
        "\n",
        "Early stopping works by testing the XGBoost model after every boosting round against a hold-out dataset and stopping the creation of additional boosting rounds (thereby finishing training of the model early) if the hold-out metric (\"rmse\" in our case) does not improve for a given number of rounds. Here you will use the early_stopping_rounds parameter in xgb.cv() with a large possible number of boosting rounds (50). Bear in mind that if the holdout metric continuously improves up through when num_boost_rounds is reached, then early stopping does not occur.\n",
        "\n",
        "- Perform 3-fold cross-validation with early stopping and \"rmse\" as your metric. Use 10 early stopping rounds and 50 boosting rounds. Specify a seed of 123 and make sure the output is a pandas DataFrame. Remember to specify the other parameters such as dtrain, params, and metrics."
      ],
      "metadata": {
        "id": "oBbo7LQCnCBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your housing DMatrix: housing_dmatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "\n",
        "# Create the parameter dictionary for each tree: params\n",
        "params = {\"objective\":\"reg:squarederror\", \"max_depth\":4}\n",
        "\n",
        "# Perform cross-validation with early stopping: cv_results\n",
        "cv_results = xgb.cv(dtrain = housing_dmatrix, nfold = 3, metrics=\"rmse\", num_boost_round=50, early_stopping_rounds=10, seed=123, params = params, as_pandas=True )\n",
        "\n",
        "# Print cv_results\n",
        "print(cv_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh0TjEtsn8kc",
        "outputId": "24bb82db-c9db-4c92-faa4-c098eeb30b8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
            "0      61708.384075      789.992240    63420.791562    2613.472325\n",
            "1      49522.546344      802.013790    53085.413747    2315.613545\n",
            "2      41169.937732      688.760982    46216.723045    2275.292419\n",
            "3      35291.530581      733.718357    41684.086762    2912.197343\n",
            "4      31046.377888      516.077566    38496.489124    2817.930645\n",
            "5      27696.206636      582.478240    36362.599330    2671.301364\n",
            "6      25408.301944      330.625199    35302.558898    2856.045380\n",
            "7      23639.812549      423.028610    34090.701206    2644.890618\n",
            "8      22255.018210      457.633545    33549.535045    2224.370383\n",
            "9      21042.204957      457.772868    33339.326024    2026.857986\n",
            "10     20190.735243      444.843073    33050.944991    1820.593939\n",
            "11     19405.436763      422.811600    32872.225752    1607.504842\n",
            "12     18825.729259      345.778797    32827.872247    1598.434460\n",
            "13     18276.857540      286.175363    32595.274062    1458.332167\n",
            "14     17817.708433      307.733726    32329.066786    1293.312181\n",
            "15     17490.368770      338.811939    32300.401008    1147.370213\n",
            "16     17127.710300      386.543502    32187.557605     959.532692\n",
            "17     16861.225088      315.905389    32085.832663     970.091560\n",
            "18     16624.823157      318.228209    32000.496006     998.552628\n",
            "19     16412.391603      306.676130    31901.414772     989.243563\n",
            "20     16101.948141      237.196507    31971.114015     928.485715\n",
            "21     15814.184923      251.737428    31811.880746    1020.025121\n",
            "22     15625.574779      237.074613    31867.686128     894.651876\n",
            "23     15454.503309      268.378017    31847.025148     789.994885\n",
            "24     15213.782639      375.634984    31833.367882     844.815287\n",
            "25     15000.887049      344.992477    31898.537101     776.634551\n",
            "26     14719.630105      308.994114    31833.534822     842.622938\n",
            "27     14492.574617      305.273386    31748.151662     752.174013\n",
            "28     14257.448180      255.950031    31699.670484     773.830394\n",
            "29     14079.358257      281.210658    31593.259747     803.802619\n",
            "30     13820.200418      329.160789    31546.480476     684.532413\n",
            "31     13623.444957      254.709185    31588.373867     654.924473\n",
            "32     13471.137892      279.473837    31567.277273     621.092081\n",
            "33     13323.024714      355.910437    31580.753850     611.629871\n",
            "34     13103.960905      324.883935    31638.756287     558.231457\n",
            "35     12915.041484      268.128395    31634.096144     567.469538\n",
            "36     12742.468103      253.082098    31551.363291     557.487521\n",
            "37     12630.599978      246.660357    31446.563558     574.462762\n",
            "38     12464.692821      273.681766    31440.780824     562.311438\n",
            "39     12315.755221      247.227348    31424.436429     600.757620\n",
            "40     12177.586271      239.645863    31419.597032     575.000375\n",
            "41     12073.000223      231.186596    31400.979313     640.855704\n",
            "42     11966.176359      205.111434    31318.818821     613.094368\n",
            "43     11785.968073      209.779764    31266.122759     602.314809\n",
            "44     11619.969729      191.148745    31252.644482     616.547269\n",
            "45     11502.363588      190.019842    31211.004245     568.956299\n",
            "46     11382.568566      268.818755    31174.535682     568.182228\n",
            "47     11236.729993      300.513827    31115.356617     542.338428\n",
            "48     11115.605347      307.209013    31106.022347     542.387109\n",
            "49     10993.824420      337.553551    31096.557556     544.377973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tuning eta**  \n",
        "It's time to practice tuning other XGBoost hyperparameters in earnest and observing their effect on model performance! You'll begin by tuning the \"eta\", also known as the learning rate.\n",
        "\n",
        "The learning rate in XGBoost is a parameter that can range between 0 and 1, with higher values of \"eta\" penalizing feature weights more strongly, causing much stronger regularization.\n",
        "\n"
      ],
      "metadata": {
        "id": "sVMFZw2spmbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your housing DMatrix: housing_dmatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
        "\n",
        "# Create the parameter dictionary for each tree (boosting round)\n",
        "params = {\"objective\":\"reg:squarederror\", \"max_depth\":3}\n",
        "\n",
        "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
        "eta_vals = [0.001, 0.01, 0.1]\n",
        "best_rmse = []\n",
        "\n",
        "# Systematically vary the eta\n",
        "for curr_val in eta_vals:\n",
        "\n",
        "    params[\"eta\"] = curr_val\n",
        "\n",
        "    # Perform cross-validation: cv_results\n",
        "    cv_results = xgb.cv(dtrain=housing_dmatrix, nfold=3, early_stopping_rounds=5, num_boost_round=10, metrics=\"rmse\", seed=123, params = params, as_pandas = True )\n",
        "\n",
        "\n",
        "\n",
        "    # Append the final round rmse to best_rmse\n",
        "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "# Print the resultant DataFrame\n",
        "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfpQoIVupohl",
        "outputId": "e90b0adf-1d71-4674-e435-6b866c9a572a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     eta     best_rmse\n",
            "0  0.001  78903.745397\n",
            "1  0.010  74293.709019\n",
            "2  0.100  47136.241898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tuning max_depth**  \n",
        "In this exercise, your job is to tune max_depth, which is the parameter that dictates the maximum depth that each tree in a boosting round can grow to. Smaller values will lead to shallower trees, and larger values to deeper trees."
      ],
      "metadata": {
        "id": "kUDiDdxuqQpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your housing DMatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "# Create the parameter dictionary\n",
        "params = {\"objective\":\"reg:squarederror\"}\n",
        "\n",
        "# Create list of max_depth values\n",
        "max_depths = [2, 5, 10, 20]\n",
        "best_rmse = []\n",
        "\n",
        "# Systematically vary the max_depth\n",
        "for curr_val in max_depths:\n",
        "\n",
        "    params[\"max_depth\"] = curr_val\n",
        "\n",
        "    # Perform cross-validation\n",
        "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, num_boost_round=10, early_stopping_rounds=5, metrics=\"rmse\", seed=123, as_pandas=True)\n",
        "\n",
        "\n",
        "\n",
        "    # Append the final round rmse to best_rmse\n",
        "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "# Print the resultant DataFrame\n",
        "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Hr4ohpqyJH",
        "outputId": "bd601124-c392-4648-b07a-1b8eeac7a93d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   max_depth     best_rmse\n",
            "0          2  37140.345524\n",
            "1          5  34301.329122\n",
            "2         10  35733.363167\n",
            "3         20  35937.767774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tuning colsample_bytree**  \n",
        "Now, it's time to tune \"colsample_bytree\". You've already seen this if you've ever worked with scikit-learn's RandomForestClassifier or RandomForestRegressor, where it just was called max_features. In both xgboost and sklearn, this parameter (although named differently) simply specifies the fraction of features to choose from at every split in a given tree. In xgboost, colsample_bytree must be specified as a float between 0 and 1."
      ],
      "metadata": {
        "id": "h_uwaY8tq0nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your housing DMatrix\n",
        "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
        "\n",
        "# Create the parameter dictionary\n",
        "params={\"objective\":\"reg:squarederror\",\"max_depth\":3}\n",
        "\n",
        "# Create list of hyperparameter values: colsample_bytree_vals\n",
        "colsample_bytree_vals = [0.1, 0.5, 0.8, 1]\n",
        "best_rmse = []\n",
        "\n",
        "# Systematically vary the hyperparameter value\n",
        "for curr_val in colsample_bytree_vals:\n",
        "\n",
        "    params[\"colsample_bytree\"] = curr_val\n",
        "\n",
        "    # Perform cross-validation\n",
        "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
        "                 num_boost_round=10, early_stopping_rounds=5,\n",
        "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
        "\n",
        "    # Append the final round rmse to best_rmse\n",
        "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
        "\n",
        "# Print the resultant DataFrame\n",
        "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=[\"colsample_bytree\",\"best_rmse\"]))\n",
        "\n",
        "# There are several other individual parameters that you can tune, such as \"subsample\",\n",
        "# which dictates the fraction of the training data that is used during any given boosting round.\n",
        "# Next up: Grid Search and Random Search to tune XGBoost hyperparameters more efficiently!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD0V_IDGrOn8",
        "outputId": "49fdf6e2-ed5b-429c-cd2f-5e26f4c1d215"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   colsample_bytree     best_rmse\n",
            "0               0.1  47958.123027\n",
            "1               0.5  35066.230191\n",
            "2               0.8  35199.444917\n",
            "3               1.0  34786.230629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid search with XGBoost**  \n",
        "Now that you've learned how to tune parameters individually with XGBoost, let's take your parameter tuning to the next level by using scikit-learn's GridSearch and RandomizedSearch capabilities with internal cross-validation using the GridSearchCV and RandomizedSearchCV functions. You will use these to find the best model exhaustively from a collection of possible parameter values across multiple parameters simultaneously. Let's get to work, starting with GridSearchCV!"
      ],
      "metadata": {
        "id": "hBsvuLYvvJy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the parameter grid: gbm_param_grid\n",
        "gbm_param_grid = {\n",
        "    'colsample_bytree': [0.3, 0.7],\n",
        "    'n_estimators': [50],\n",
        "    'max_depth': [2, 5]\n",
        "}\n",
        "\n",
        "# Instantiate the regressor: gbm\n",
        "gbm = xgb.XGBRegressor()\n",
        "\n",
        "# Perform grid search: grid_mse\n",
        "grid_mse = GridSearchCV(param_grid=gbm_param_grid, estimator=gbm, scoring=\"neg_mean_squared_error\", cv=4, verbose=1)\n",
        "\n",
        "\n",
        "# Fit grid_mse to the data\n",
        "grid_mse.fit(X, y)\n",
        "\n",
        "# Print the best parameters and lowest RMSE\n",
        "print(\"Best parameters found: \", grid_mse.best_params_)\n",
        "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEs_aYtswJ3f",
        "outputId": "fd373033-dfa9-4c24-a499-1bd0aeaee8f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
            "Best parameters found:  {'colsample_bytree': 0.7, 'max_depth': 2, 'n_estimators': 50}\n",
            "Lowest RMSE found:  30948.246864725632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When should you use grid search and random search?**  \n",
        "Now that you've seen some of the drawbacks of grid search and random search, which of the following most accurately describes why both random search and grid search are non-ideal search hyperparameter tuning strategies in all scenarios?\n",
        "\n",
        "->\n",
        "The search space size can be massive for Grid Search in certain cases, whereas for Random Search the number of hyperparameters has a significant effect on how long it takes to run.\n",
        "\n",
        "[ This is why random search and grid search should not always be used. Nice! ]"
      ],
      "metadata": {
        "id": "St-FpuFJx4Pr"
      }
    }
  ]
}