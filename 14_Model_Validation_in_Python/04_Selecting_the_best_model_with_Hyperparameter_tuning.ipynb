{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDwOtvTtw+lxT9hl2pnjzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohanrathod7/my-ml-labs/blob/main/14_Model_Validation_in_Python/04_Selecting_the_best_model_with_Hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Selecting the best model with Hyperparameter tuning.\n"
      ],
      "metadata": {
        "id": "69GNV3tpDLy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUPpAj0HoP6i"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "# Import confusion matrix and train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression, LinearRegression\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Rohanrathod7/my-ml-labs/main/13_Feature_Engineering_for_Machine_Learning_in_Python/dataset/inaugural_speeches.csv\"\n",
        "# Read the CSV file\n",
        "\n",
        "# Apply pd.to_numeric only to relevant columns, excluding 'text'\n",
        "speech_df = pd.read_csv(url)\n",
        "numeric_cols = ['Name', 'Inaugural Address', 'Date'] # Assuming these should be numeric if possible\n",
        "for col in numeric_cols:\n",
        "    speech_df[col] = pd.to_numeric(speech_df[col], errors='coerce')\n",
        "\n",
        "display(speech_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to hyperparameter tuning"
      ],
      "metadata": {
        "id": "EqrdBw-QYsI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Creating Hyperparameters**  \n",
        "For a school assignment, your professor has asked your class to create a random forest model to predict the average test score for the final exam.\n",
        "\n",
        "After developing an initial random forest model, you are unsatisfied with the overall accuracy. You realize that there are too many hyperparameters to choose from, and each one has a lot of possible values. You have decided to make a list of possible ranges for the hyperparameters you might use in your next model.\n",
        "\n",
        "Your professor has provided de-identified data for the last ten quizzes to act as the training data. There are 30 students in your class."
      ],
      "metadata": {
        "id": "55ifAc7HZIms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import random\n",
        "\n",
        "# Placeholder variables (you should replace these with your actual ranges)\n",
        "max_depth = [10, 20, 30, None]\n",
        "min_samples_split = [2, 5, 10]\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "\n",
        "# Fill in rfr using your variables\n",
        "rfr = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=random.choice(max_depth),\n",
        "    min_samples_split=random.choice(min_samples_split),\n",
        "    max_features=random.choice(max_features))\n",
        "\n",
        "# Print out the parameters\n",
        "print(rfr.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrQzTlaGZZig",
        "outputId": "51fa3013-8602-495a-bd42-5eff68d98a8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 20, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomizedSearchCV\n"
      ],
      "metadata": {
        "id": "YuPZ2U1EZ2tK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing for RandomizedSearch**  \n",
        "Last semester your professor challenged your class to build a predictive model to predict final exam test scores. You tried running a few different models by randomly selecting hyperparameters. However, running each model required you to code it individually.\n",
        "\n",
        "After learning about RandomizedSearchCV(), you're revisiting your professors challenge to build the best model. In this exercise, you will prepare the three necessary inputs for completing a random search."
      ],
      "metadata": {
        "id": "Usf9e-lXadDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "# Finish the dictionary by adding the max_depth parameter\n",
        "param_dist = {\"max_depth\": [2, 4, 6, 8],\n",
        "              \"max_features\": [2, 4, 6, 8, 10],\n",
        "              \"min_samples_split\": [2, 4, 8, 16]}\n",
        "\n",
        "# Create a random forest regression model\n",
        "rfr = RandomForestRegressor(n_estimators=10, random_state=1111)\n",
        "\n",
        "# Create a scorer to use (use the mean squared error)\n",
        "scorer = make_scorer(mean_squared_error)\n",
        "\n",
        "# To use RandomizedSearchCV(), you need a distribution dictionary, an estimator,\n",
        "# and a scorerâ€”once you've got these, you can run a random search to find the best parameters for your model."
      ],
      "metadata": {
        "id": "c356Gg0iapsk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing RandomizedSearchCV**  \n",
        "You are hoping that using a random search algorithm will help you improve predictions for a class assignment. You professor has challenged your class to predict the overall final exam average score.\n",
        "\n",
        "In preparation for completing a random search, you have created:\n",
        "\n",
        "- param_dist: the hyperparameter distributions\n",
        "- rfr: a random forest regression model\n",
        "- scorer: a scoring method to use"
      ],
      "metadata": {
        "id": "_sKW_mkWaxzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the method for random search\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Build a random search using param_dist, rfr, and scorer\n",
        "random_search =\\\n",
        "    RandomizedSearchCV(\n",
        "        estimator=rfr,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=10,\n",
        "        cv=5,\n",
        "        scoring=scorer)\n",
        "\n",
        "# Although it takes a lot of steps, hyperparameter tuning with random search is well worth it and can improve the accuracy of your models.\n",
        "# Plus, you are already using cross-validation to validate your best model"
      ],
      "metadata": {
        "id": "Tf-DIT4ta5Bm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting the best precision model**  \n",
        "Your boss has offered to pay for you to see three sports games this year. Of the 41 home games your favorite team plays, you want to ensure you go to three home games that they will definitely win. You build a model to decide which games your team will win.\n",
        "\n",
        "To do this, you will build a random search algorithm and focus on model precision (to ensure your team wins). You also want to keep track of your best model and best parameters, so that you can use them again next year (if the model does well, of course). You have already decided on using the random forest classification model rfc and generated a parameter distribution param_dist."
      ],
      "metadata": {
        "id": "waet4PHDbrO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, make_scorer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Create a precision scorer\n",
        "precision = make_scorer(precision_score)\n",
        "\n",
        "# Define rfc (Random Forest Classifier)\n",
        "rfc = RandomForestClassifier(random_state=1111)\n",
        "\n",
        "# Create placeholder data for X and y\n",
        "# Replace with your actual data\n",
        "X = np.random.rand(100, 10) # 100 samples, 10 features\n",
        "y = np.random.randint(0, 2, 100) # 100 labels (0 or 1)\n",
        "\n",
        "\n",
        "# Finalize the random search\n",
        "rs = RandomizedSearchCV(\n",
        "  estimator=rfc, param_distributions=param_dist,\n",
        "  scoring = precision,\n",
        "  cv=5, n_iter=10, random_state=1111)\n",
        "rs.fit(X, y)\n",
        "\n",
        "# print the mean test scores:\n",
        "print('The accuracy for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
        "# print the best model score:\n",
        "print('The best accuracy for a single model was: {}'.format(rs.best_score_))\n",
        "\n",
        "# Your model's precision was 93%! The best model accurately predicts a winning game 93% of the time.\n",
        "# If you look at the mean test scores, you can tell some of the other parameter sets did really poorly.\n",
        "# Also, since you used cross-validation, you can be confident in your predictions. Well done!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY8ujBRIb84W",
        "outputId": "e5709be5-f48d-4ce1-8426-da356ad0889f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for each run was: [0.51186869 0.5265873  0.52058442 0.46214896 0.51697802 0.46444444\n",
            " 0.50595238 0.51642247 0.53115385 0.4613986 ].\n",
            "The best accuracy for a single model was: 0.5311538461538461\n"
          ]
        }
      ]
    }
  ]
}